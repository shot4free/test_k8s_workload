---

registry:
  image:
    tag: v2.10.1-gitlab
  hpa:
    minReplicas: 30
    maxReplicas: 150
  nodeSelector:
    type: registry
  resources:
    requests:
      cpu: 250m
      memory: 3G

gitlab:
  mailroom:
    enabled: true
  webservice:
    enabled: false
    nodeSelector:
      # This will be updated to a dedicated nodepool once
      # https://gitlab.com/gitlab-com/gl-infra/delivery/-/issues/1068
      # is complete
      type: default
  sidekiq:
    podLabels:
      tier: sv
      type: sidekiq

    pods:
      - name: catchall
        concurrency: 15
        minReplicas: 56
        maxReplicas: 100
        nodeSelector:
          type: catchall
        podLabels:
          shard: catchall
        queues: |
          name=default|name=adjourned_project_deletion|name=admin_emails|name=authorized_project_update:authorized_project_update_project_create|name=authorized_project_update:authorized_project_update_project_group_link_create|name=authorized_project_update:authorized_project_update_user_refresh_over_user_range|name=authorized_project_update:authorized_project_update_user_refresh_with_low_urgency|name=ci_batch_reset_minutes|name=container_repository:cleanup_container_repository|name=container_repository:delete_container_repository|name=cronjob:adjourned_group_deletion|name=cronjob:adjourned_projects_deletion_cron|name=cronjob:clear_shared_runners_minutes|name=cronjob:container_expiration_policy|name=cronjob:environments_auto_stop_cron|name=cronjob:geo_container_repository_sync_dispatch|name=cronjob:geo_file_download_dispatch|name=cronjob:geo_metrics_update|name=cronjob:geo_prune_event_log|name=cronjob:geo_registry_sync|name=cronjob:geo_repository_sync|name=cronjob:geo_repository_verification_primary_batch|name=cronjob:geo_repository_verification_secondary_scheduler|name=cronjob:geo_repository_verification_secondary_shard|name=cronjob:geo_scheduler_per_shard_scheduler|name=cronjob:geo_scheduler_primary_per_shard_scheduler|name=cronjob:geo_scheduler_secondary_per_shard_scheduler|name=cronjob:geo_secondary_registry_consistency|name=cronjob:geo_sidekiq_cron_config|name=cronjob:historical_data|name=cronjob:issue_due_scheduler|name=cronjob:iterations_update_status|name=cronjob:ldap_all_groups_sync|name=cronjob:ldap_sync|name=cronjob:metrics_dashboard_schedule_annotations_prune|name=cronjob:pages_domain_ssl_renewal_cron|name=cronjob:pages_domain_verification_cron|name=cronjob:partition_creation|name=cronjob:personal_access_tokens_expiring|name=cronjob:prune_old_events|name=cronjob:prune_web_hook_logs|name=cronjob:remove_expired_group_links|name=cronjob:remove_unreferenced_lfs_objects|name=cronjob:sync_seat_link|name=cronjob:update_container_registry_info|name=cronjob:users_create_statistics|name=cronjob:vulnerabilities_statistics_schedule|name=delete_user|name=deployment:deployments_forward_deployment|name=elastic_full_index|name=elastic_indexing_control|name=elastic_namespace_indexer|name=elastic_namespace_rollout|name=geo:geo_batch_project_registry|name=geo:geo_batch_project_registry_scheduler|name=geo:geo_blob_verification_primary|name=geo:geo_container_repository_sync|name=geo:geo_design_repository_shard_sync|name=geo:geo_design_repository_sync|name=geo:geo_event|name=geo:geo_file_download|name=geo:geo_file_registry_removal|name=geo:geo_file_removal|name=geo:geo_hashed_storage_attachments_migration|name=geo:geo_hashed_storage_migration|name=geo:geo_project_sync|name=geo:geo_rename_repository|name=geo:geo_repositories_clean_up|name=geo:geo_repository_cleanup|name=geo:geo_repository_destroy|name=geo:geo_repository_shard_sync|name=geo:geo_repository_verification_primary_shard|name=geo:geo_repository_verification_primary_single|name=geo:geo_repository_verification_secondary_single|name=geo:geo_scheduler_primary_scheduler|name=geo:geo_scheduler_scheduler|name=geo:geo_scheduler_secondary_scheduler|name=geo:geo_secondary_repository_backfill|name=group_export|name=group_import|name=jira_connect:jira_connect_sync_branch|name=jira_connect:jira_connect_sync_merge_request|name=ldap_group_sync|name=mail_scheduler:mail_scheduler_issue_due|name=metrics_dashboard_prune_old_annotations|name=package_repositories:packages_nuget_extraction|name=personal_access_tokens:personal_access_tokens_groups_policy|name=personal_access_tokens:personal_access_tokens_instance_policy|name=phabricator_import_import_tasks|name=pipeline_background:ci_build_trace_chunk_flush|name=pipeline_background:ci_daily_build_group_report_results|name=pipeline_background:ci_pipeline_success_unlock_artifacts|name=pipeline_background:ci_ref_delete_unlock_artifacts|name=pipeline_creation:run_pipeline_schedule|name=pipeline_processing:ci_build_prepare|name=pipeline_processing:ci_resource_groups_assign_resource_from_resource_group|name=propagate_integration|name=repository_push_audit_event|name=service_desk_email_receiver|name=sync_seat_link_request|name=todos_destroyer:todos_destroyer_confidential_issue|name=todos_destroyer:todos_destroyer_entity_leave|name=todos_destroyer:todos_destroyer_group_private|name=todos_destroyer:todos_destroyer_private_features|name=todos_destroyer:todos_destroyer_project_private|name=unassign_issuables:members_destroyer_unassign_issuables|name=upload_checksum|name=vulnerabilities_statistics_adjustment|name=vulnerability_exports_export_deletion
        resources:
          requests:
            cpu: 800m
            memory: 1G
          limits:
            cpu: 1.5
            memory: 2G
      - name: memory-bound
        concurrency: 1
        minReplicas: 4
        maxReplicas: 16
        nodeSelector:
          type: memory-bound
        podLabels:
          shard: memory-bound
        queues: resource_boundary=memory
        resources:
          requests:
            cpu: 50m
            memory: 650M
          limits:
            cpu: 2
            memory: 8G
        extraVolumeMounts: |
          - name: sidekiq-shared
            mountPath: /srv/gitlab/shared
            readOnly: false
        extraVolumes: |
          - name: sidekiq-shared
            emptyDir:
              sizeLimit: 70G
      # Run background migrations in their own shard
      - name: database-throttled
        concurrency: 5 # Discussion on this value in https://gitlab.com/gitlab-com/gl-infra/k8s-workloads/gitlab-com/-/merge_requests/276/diffs#note_367270352
        minReplicas: 1
        maxReplicas: 1
        nodeSelector:
          type: default
        podLabels:
          shard: database-throttled
        queues: feature_category=database&urgency=throttled
        resources:
          requests:
            cpu: 50m
            memory: 650M
          limits:
            cpu: 1.5
            memory: 6G
      # Run Gitaly Storage Migrations on their own shards
      # https://gitlab.com/gitlab-com/gl-infra/scalability/-/issues/436
      # Allow up to a maximum of 24 concurrent gitaly-throttled jobs
      - name: gitaly-throttled
        concurrency: 8
        minReplicas: 1
        maxReplicas: 3
        nodeSelector:
          type: default
        podLabels:
          shard: gitaly-throttled
        queues: feature_category=gitaly&urgency=throttled
        resources:
          requests:
            cpu: 50m
            memory: 650M
          limits:
            cpu: 1.5
            memory: 6G
      - name: elasticsearch
        concurrency: 2
        minReplicas: 2
        maxReplicas: 8
        nodeSelector:
          type: default
        podLabels:
          shard: elasticsearch
        queues: feature_category=global_search&urgency=throttled
        resources:
          requests:
            cpu: 50m
            memory: 650M
          limits:
            cpu: 2
            memory: 8G
      # Production resources for this shard discussed in
      # https://gitlab.com/gitlab-com/gl-infra/infrastructure/-/issues/10445
      # https://gitlab.com/gitlab-com/gl-infra/delivery/-/issues/901
      - name: low-urgency-cpu-bound
        concurrency: 5
        minReplicas: 10
        maxReplicas: 100
        nodeSelector:
          type: low-urgency-cpu-bound
        podLabels:
          shard: low-urgency-cpu-bound
        queues: resource_boundary=cpu&urgency=default,low
        resources:
          requests:
            cpu: 80m
            memory: 5G
          limits:
            cpu: 1.5
            memory: 6G
      # Production resources for urgent-cpu-bound discussed in
      # https://gitlab.com/gitlab-com/gl-infra/infrastructure/-/issues/10639
      - name: urgent-cpu-bound
        concurrency: 5
        hpa:
          targetAverageValue: 300m
        minReplicas: 30
        maxReplicas: 84
        nodeSelector:
          type: urgent-cpu-bound
        podLabels:
          shard: urgent-cpu-bound
        queues: resource_boundary=cpu&urgency=high&tags!=requires_disk_io
        resources:
          requests:
            cpu: 588m
            memory: 800M
          limits:
            cpu: 2
            memory: 3G
      # Production resources for this shard discussed in
      # https://gitlab.com/gitlab-com/gl-infra/infrastructure/-/issues/10446
      - name: urgent-other
        concurrency: 5
        minReplicas: 110
        maxReplicas: 110
        nodeSelector:
          type: urgent-other
        podLabels:
          shard: urgent-other
        queues: resource_boundary!=cpu&urgency=high
        resources:
          requests:
            cpu: 80m
            memory: 1G
          limits:
            cpu: 1.5
            memory: 6G

global:
  appConfig:
    incomingEmail:
      enabled: true
    omniauth:
      providers:
        - secret: gitlab-google-oauth2-v1
        - secret: gitlab-twitter-oauth2-v1
        - secret: gitlab-github-oauth2-v1
        - secret: gitlab-bitbucket-oauth2-v1
        - secret: gitlab-group-saml-oauth2-v1
        - secret: gitlab-salesforce-oauth2-v1
  email:
    reply_to: noreply@gitlab.com

  hosts:
    gitlab:
      name: gitlab.com

  psql:
    prepared_statements: false
    load_balancing:
      discover:
        nameserver: consul-consul-dns.consul
        record: db-replica.service.consul.
        record_type: SRV
        port: 53
        use_tcp: true

  smtp:
    enabled: true
    password:
      key: secret
      secret: gitlab-smtp-credential-v1
nginx-ingress:
  enabled: false
